---
layout: post
title: "√âtude de cas : d√©faillance machine - test de conformit√© √† une moyenne pour un grand √©chantillon."
date: 2024-09-27
categories: ["Analyse de donn√©es", "Science des donn√©es", "Test de conformit√©"]
tags: ["Python", "Test statistiques", "Conformti√©"]
description: "Cette √©tude de cas reprend la mise en place du test de conformit√© √† une moyenne. Notamment, dans le cas d'un √©chantillon de grande taille, on s'int√©resse √† la d√©faillance d'une machine lors de l'usinage d'une pi√®ce."
---

# Test de conformit√© d‚Äôune moyenne.

Apr√®s usinage, on pr√©l√®ve **au hasard 100 pi√®ces** dont on mesure le diam√®tre. Chaque pi√®ce doit avoir un **diam√®tre de 58mm**. Apr√®s mesure de chacune d‚Äôentre elle, on s‚Äôaper√ßoit que le **diam√®tre moyen** est de **58.2mm**. Il semblerait que la qualit√© d‚Äôusinage des pi√®ces ne soit pas au rendez-vous. Toutefois, il se peut aussi que cet √©cart entre le diam√®tre souhait√© (58mm) et le diam√®tre observ√© (58.5mm) soit le fruit du hasard. Cela signifierai que la diff√©rence observ√©e est due √† la fa√ßon dont on a s√©lectionn√© les pi√®ces : si d‚Äôautres pi√®ces avait √©t√© s√©lectionn√©es on aurait observ√© une diff√©rence autre ou pas de diff√©rence du tout. 

La **statistique inferentielle** permet de **lever se doute** entre **fruit du hasard** (√©chantillonnage) et ph√©nom√®ne observable dans la **population g√©n√©rale** (population parente). 

Voici les donn√©es recueillies.

```python
import pandas as pd
import numpy as np
import random
random.seed(10)

moy_cible = 58.00
n = 100

data = np.random.normal(loc=58.2, scale=0.2, size=n)
serie = pd.Series(data)

moy_obs = serie.mean()
print(moy_obs)

	58.2031
```

Pour acc√©der au notebook de l'√©tude de cas, c'est par <a href="{{ site.baseurl }}/assets/pdf/conformite_grand_echantillon.pdf"> ici </a>. 

## Test d‚Äôhypoth√®ses.
Pour r√©pondre √† la probl√©matique du d√©faut d‚Äôusinage, on peut utiliser un **test de conformit√© √† la moyenne**. Il s‚Äôagit de **v√©rifier que la diff√©rence observ√©e n‚Äôest pas sp√©cifique √† l‚Äô√©chantillon s√©lectionn√© et donc imputable √† la population globale**. 

Selon les contextes, on peut vouloir v√©rifier que cette diff√©rence observ√©e est strictement plus grande ou plus petite que le param√®tre d‚Äôune population cible. Par exemple, s‚Äôil s‚Äôagit de v√©rifier la conformit√© d‚Äôune ampoule, il ne faut pas que sa dur√©e de vie soit inf√©rieure mais si elle est sup√©rieure, tant mieux. √Ä l‚Äôinverse, si on s‚Äôint√©resse au poids moyen contenu dans un sachet de bonbon, ni l‚Äôentreprise, ni le client ne voudront √™tre l√©s√©s : la quantit√© moyenne ne devra pas diff√©r√©e de celle convenu lors de la mise en production et de celle affich√©e sur l‚Äôemballage. En outre, c‚Äôest ce contexte qui va d√©finir la structure du test statistique : soit il sera bilat√©ral, soit unilat√©ral (√† gauche ou √† droite). 

### Jeu des hypoth√®ses. 
Dans notre contexte, il s‚Äôagit d‚Äôun test bilat√©ral. Sous l‚Äôhypoth√®se nulle, les deux moyennes sont identiques : moyenne observ√©e = moyenne de r√©f√©rence. L‚Äôhypoth√®se alternative (celle qu‚Äôon souhaite d√©montrer) stipule que les deux moyennes sont diff√©rentes. Formellement,

$$H_0 : moy_{obs} = moy_{cible},$$
$$H_1 : moy_{obs} \neq moy_{cible}.$$

La moyenne cible vaut 58mm et la moyenne observ√©e 58.2mm. 

### Risque d‚Äôerreur.
Le **risque d‚Äôerreur** est un **risque auquel on accepte de se soumettre lors du rejet de l‚Äôhypoth√®se nulle**. Pr√©cis√©ment, avec un risque d‚Äôerreur de 5%, on accepte de rejeter l‚Äôhypoth√®se nulle √† tord avec 5% de chances. 

On fixe notre risque d‚Äôerreur $$\alpha$$ √† 5%.

```python
alpha = 0.05
```

### Validit√© du test. 
Avant de fournir la statistique test, sachez que la validit√© du test repose sur la distribution normale de la moyenne observ√©e. Ainsi, si votre **√©chantillon est suffisamment grand (n>30)** vous pouvez appliquer le Th√©or√®me Central Limite (TCL) : il stipule qu‚Äô√† mesure que l‚Äô√©chantillon croit (√† l‚Äôinfini) l‚Äôesp√©rance de moyennes de sous √©chantillons est normalement distribu√©e quel que soit la distribution initiale des sous-√©chantillons ind√©pendants[^1]. Cependant, si votre **√©chantillon est petit (n<30)** vous devez v√©rifier que sa distribution est gaussienne pour ne pas compromettre la validit√© de vos conclusions. 

√âgalement, la statistique de test repose sur l‚Äô**√©cart type de la population**. Aussi, si vous ne connaissez pas la variance de la population vous devez fournir une **estimation sans biais** de ce param√®tre. C‚Äôest-√†-dire que vous devez corriger la variance de l‚Äô√©chantillon d‚Äôun facteur . 

Dans notre cas, l‚Äô√©chantillon comprend 100 individus et la variance de la population est inconnue. Nous pouvons donc appliquer le TCL et utiliser une estimation sans biais de la variance. 

### Statistique de test. 
La statistique de test est la suivante : 

$$t = \frac{moy_{obs} - moy_{cible}}{\frac{s'}{\sqrt{n}}},$$

o√π $$s'$$ est l‚Äôestimation sans biais de l‚Äô√©cart-type.

Cette statistique de test suit une **loi de Student √† n-1 degr√©s de libert√©** (ddl) : $$t_{n-1ddl;0.05}$$. 

### Calcul de la statistique de test t.
Pour calculer notre statistique de test il nous manque l‚Äôestimation sans biais de l‚Äô√©cart-type. 

```python
import numpy as np

std = np.std(serie ,ddof=1)
```
 
On peut calculer la statistique de test. 


```python
t = (moy_obs - moy_cible) / (std/np.sqrt(n))
print(t)

	9.036274695663673
```

### Quantile de la loi de Student. 
On va maintenant comparer cette statistique au quantile de la loi de Student pour n-1 ddl et un risque d‚Äôerreur de 5%. 

```python
from scipy import stats
quantile = stats.t.ppf(1-(0.05/2), n-1)
print(quantile)

    1.9842169515086827
```

Avec un risque d'erreur de 5%, on peut rejeter l'hypoth√®se nulle d'√©galit√© des moyennes. En effet, d'apr√®s les relev√©s effectu√©s, nous avons suffisamment d'√©vidences pour conclure √† la d√©faillance machine.

### Pvalue. 
Calculons la probabilit√© d‚Äôobserver une statistique au moins aussi grande. Pour √ßa, on va utiliser la fonction de r√©partition cumulative. 

```python
pvalue = 2 * (1-stats.f.cdf(1-(0.05/2), 100-1))
print(pvalue)

    1.3766765505351941e-14
```

La probabilit√© d'observer une statistique de test au moins aussi extr√™me est largement inf√©rieur au seuil de singificativit√© de 5%. On peut donc conclure √† la d√©faillance machine. 

## Intervalle de confiance. 
Pour v√©rifier la conformit√© de notre usinage on peut utiliser une autre m√©thode inferentielle : l‚Äôintervalle de confiance. On fixe le risque d‚Äôerreur √† 5%. L‚Äôintervalle de confiance √† 95% est :

$$IC_{95} = moy_{obs} \pm t_{n-1 ddl ; \alpha} * \frac{s'}{\sqrt{n}}.$$

Cet intervalle de confiance nous dit que si on utilisait 100 √©chantillons diff√©rents, 95 intervalles de confiance sur 100 contiendraient la vrai moyenne de la population. Autrement dit, si la moyenne cible n‚Äôappartient pas √† l‚Äô$$IC_{95}$$, on a 5 chances sur 100 de conclure √† tord √† la d√©faillance de la machine. 

On trouve,

```python
ic_inf = moy_obs - quantile * (std/np.sqrt(n))

ic_sup = moy_obs + quantile * (std/np.sqrt(n))

print(ic_inf, moy_cible, ic_sup)

    58.171463255736086
    58.0
    58.26795148964892
```
Effectivement, la moyenne cible n'appartient pas √† l'intervalle de confiance de notre moyenne observ√©e. Il est donc peu probable qu'on conclut √† tord √† la d√©faillance machine.

## Test de Student pour 1 √©chantillon. 
Finalement, et pour v√©rifier notre d√©marche, on peut utiliser la fonction *ttest_1samp* du module *scipy.stats*. 
Avec cette fonction vous obtiendrez la statistique de test et la pvalue. √âgalement, depuis la *version 1.10.0* de scipy vous disposez d‚Äôune m√©thode pour obtenir l‚Äôintervalle de confiance (avec un risque d‚Äôerreur donn√©) ainsi que le nombre de degr√©s de libert√©. 

```python
from scipy.stats import ttest_1samp as test_conformite 

results = test_conformite(a=serie, popmean=moy_cible, alternative=‚Äòtwo-sided‚Äô, alpha=0.05)

display(results.statistic, results.pvalue)

    9.036274695663673
    1.3814898377141245e-14
    
display(results.df)

    99

display(results.confidence_interval(confidence_level=0.95))

    ConfidenceInterval(low=58.171463255736086, high=58.26795148964892)
```
Nos observations pr√©c√©dentes √©taient bonnes. Avec un risque d'erreur de 5%, on peut rejeter l'hypoth√®se nulle. On conclut donc √† la d√©faillance significative de la machine.

Voila, nous sommes arriv√©s au bout de notre Test de conformit√© √† une moyenne.

 √Ä bient√¥t ! ü§ì
 
 [^1]: Par exemple, si on consid√®re les distributions des salaires de 100 entreprises, celles-ci ont peu de chance d'√™tre normales puisque des hauts salaires √©tirent notre distribution. Cependant, si on prend le salaire moyen de chacune des entreprises, alors il est tr√®s probable que sa distribution ressemble √† une gaussienne. 
